# Inception - Layered trust for AI inference. AI outputs are released only after decentralized validation.

Inception is a trust-conditional execution layer that prevents AI outputs from being accepted or acted upon unless decentralized validators approve them. It holds AI inference results in escrow, validates them via redundant inference and scoring, and only releases outputs that meet configurable acceptance criteria.

---

## ðŸš¨ Problem

Modern AI systems are increasingly agentic, with the ability to act on infrastructure, sign transactions, and make high-impact decisions. Current inference is fundamentally unsafe because:

- Inference is unverified: no proof that the model actually ran, the correct model/version was used, or the output wasnâ€™t altered.
- Single-model outputs are brittle: LLMs hallucinate, fail silently, and produce inconsistent results.
- Agents have no objective mechanism for deciding when to act: they lack confidence signals and independent validation.
- There is no concept of conditional AI execution: outputs are always released, even when unsafe.

**Core Gap:** There is no mechanism to condition the release of AI outputs on decentralized trust and validation.

---

## ðŸ’¡ Proposed Solution â€” Inference Escrow

Inference Escrow treats AI inference like a transaction that must clear escrow before being accepted. Instead of assuming AI outputs are valid, the system:

- Holds outputs in escrow
- Runs redundant, independent inference (Proof of Inference â€” PoI)
- Scores outputs for usefulness (Proof of Useful Work â€” PoUW)
- Releases, rejects, or escalates results based on configurable rules

One-line definition: Inference Escrow is a trust-conditional execution layer where AI outputs are released only if decentralized validators approve them.

---

## ðŸ§  Why this is new

No existing AI system provides conditional output release based on independent validator approval and verifiable proof of execution. This primitive requires decentralized inference networks (e.g., Cortensor) to provide independence, proofs, and economic incentives.

---

## ðŸ—ï¸ Conceptual Architecture

```
Client / Agent
   â†“
Inference Escrow API
   â†“
Cortensor Session (PoI)
   â†“
Redundant Inference (N nodes)
   â†“
Validator Scoring (PoUW)
   â†“
Escrow Decision Engine
   â†“
Outcome: RELEASE | REJECT | ESCALATE
```

--- 

## ðŸ” Escrow Decision States

| State      | Meaning                                  |
|------------|------------------------------------------|
| RELEASE    | Output is trustworthy and safe to act on |
| REJECT     | Output failed validation and must not be used |
| ESCALATE   | Human or higher-cost validation required |

Each decision includes a confidence score, validator evidence, and disagreement metrics.

---

## ðŸ” Validator Pipeline (PoUW)

Combined confidence formula (example):

```ts
confidence =
  0.5 * semanticAgreement +
  0.3 * rubricScore +
  0.2 * deterministicScore;
```

Thresholds (example):

- `>= 0.85` â†’ RELEASE
- `< 0.5` â†’ REJECT
- else â†’ ESCALATE

Validators include agreement checks, LLM rubric scoring, deterministic rules (regex, JSON schema, numeric checks), and embedding similarity.

---

## ðŸ“¦ Evidence Bundle

A structured proof produced for every escrow decision. Example:

```json
{
  "decision": "RELEASE",
  "confidence": 0.89,
  "validators": 4,
  "agreement": "high",
  "proofs": [
    { "node": "node-1", "proof": "..." },
    { "node": "node-2", "proof": "..." }
  ]
}
```

Evidence bundles are JSON artifacts that can optionally be anchored (IPFS, on-chain) for public verifiability.

---

## ðŸ§ª API (MVP)

- `POST /infer-escrow`
  - Request: `{ prompt, escrowRules?, metadata? }`
  - Response (async or sync): `{ id, status, decision?, evidence? }`

- `GET /escrow/:id`
  - Returns full record, evidence bundle, and decision trace.

Example `curl`:

```bash
curl -X POST http://localhost:3000/infer-escrow \
  -H "Content-Type: application/json" \
  -d '{"prompt":"Summarize the security findings","escrowRules":{"threshold":0.85}}'
```

---

## ðŸ—‚ï¸ Folder Structure (MVP)

```
inference-escrow/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.ts
â”‚   â”œâ”€â”€ app.ts
â”‚   â”œâ”€â”€ routes/escrow.routes.ts
â”‚   â”œâ”€â”€ cortensor/
â”‚   â”‚   â”œâ”€â”€ client.ts
â”‚   â”‚   â”œâ”€â”€ session.ts
â”‚   â”‚   â””â”€â”€ inference.ts
â”‚   â”œâ”€â”€ escrow/
â”‚   â”‚   â”œâ”€â”€ engine.ts
â”‚   â”‚   â”œâ”€â”€ decision.ts
â”‚   â”‚   â””â”€â”€ types.ts
â”‚   â”œâ”€â”€ validators/
â”‚   â”‚   â”œâ”€â”€ agreement.ts
â”‚   â”‚   â”œâ”€â”€ rubric.ts
â”‚   â”‚   â””â”€â”€ deterministic.ts
â”‚   â”œâ”€â”€ evidence/bundle.ts
â”‚   â”œâ”€â”€ storage/db.ts
â”‚   â””â”€â”€ index.ts
â”œâ”€â”€ diagrams/
â”œâ”€â”€ README.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ package.json
â””â”€â”€ LICENSE
```

---


## ðŸ† Hackathon #3 â€” Short summary

We are building this project for **Hackathon #3 (Cortensor)** â€” focused on agentic applications, PoI/PoUW validation, tooling, and public goods. Key points:

- **Objective:** Build PoC apps, validators, or developer tooling that leverage Cortensorâ€™s decentralized inference (PoI/PoUW).
- **Focus areas:** Agentic assistants, validation utilities, app stores, SDKs/CLIs, observability, and public/free inferencing.
- **Timeline:** Kick-off: Nov 21, 2025 Â· Submission deadline: Jan 4, 2026.
- **Prize pool (high-level):** Top prizes range from $800 to $50 (in $COR equivalents); ongoing grants available for standout projects.
- **How to participate:** Join Discord (discord.gg/cortensor), build in the community repo, and submit a public repo with a demo and README.

This README highlights which hackathon we're participating in and what to prioritize.

---

## ðŸ“„ License

This project is released under the MIT License. See [LICENSE](LICENSE) for details.

---

## ðŸ™‹ Contributing

Contributions are welcome. Please open issues for bugs and feature requests. For major changes, open a PR and include tests and docs.

---

## Acknowledgements

This project is inspired by cutting-edge work in decentralized inference networks and trust primitives for agentic AI.

---
